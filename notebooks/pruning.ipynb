{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "import torchvision.models as models\n",
    "from torch.onnx import export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_onnx(\n",
    "    model,\n",
    "    output_file,\n",
    "    input_shape=(1, 3, 224, 224),\n",
    "):\n",
    "    model.eval()\n",
    "    input_tensor = torch.randn(input_shape)\n",
    "    input_names = [\"input\"]\n",
    "    output_names = [\"output\"]\n",
    "    export(model, input_tensor, output_file, verbose=False, input_names=input_names, output_names=output_names)\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推論時間（密）: 0.0274 秒\n"
     ]
    }
   ],
   "source": [
    "# モデルを読み込む\n",
    "model = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
    "model_to_onnx(model, \"resnet50_dense.onnx\") # 密モデルを ONNX 形式で保存\n",
    "\n",
    "input_image = torch.ones((1, 3, 224, 224))\n",
    "output = model(input_image)  # ウォームアップ\n",
    "\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    output = model(input_image)\n",
    "end_time = time.time()\n",
    "print(f\"推論時間（密）: {end_time - start_time:.4f} 秒\")\n",
    "# Intel Core i7-12700 で 0.0277 秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = [\n",
    "    (module, \"weight\") for module in model.modules() if isinstance(module, torch.nn.Conv2d)\n",
    "]  # すべての畳み込み層を枝刈り対象にする\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.9,\n",
    ")  # 大域的・非構造・強度枝刈り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推論時間（枝刈り直後）: 0.0362 秒\n"
     ]
    }
   ],
   "source": [
    "model(input_image)  # ウォームアップ\n",
    "\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    output = model(input_image)\n",
    "end_time = time.time()\n",
    "print(f\"推論時間（枝刈り直後）: {end_time - start_time:.4f} 秒\")\n",
    "# Intel Core i7-12700 で 0.0359 秒\n",
    "# マスクを都度適用しているのでかえって遅くなる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オプション: 再訓練をここで行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in model.modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.remove(module, \"weight\")  # 永続化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) Zero-Ratio: 40.20%\n",
      "Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 47.51%\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) Zero-Ratio: 68.17%\n",
      "Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 54.78%\n",
      "Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 51.41%\n",
      "Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 56.46%\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) Zero-Ratio: 63.88%\n",
      "Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 55.66%\n",
      "Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 53.83%\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) Zero-Ratio: 60.34%\n",
      "Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 60.27%\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 54.48%\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) Zero-Ratio: 75.34%\n",
      "Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 68.58%\n",
      "Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) Zero-Ratio: 82.97%\n",
      "Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 79.05%\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) Zero-Ratio: 80.78%\n",
      "Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 74.43%\n",
      "Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 75.51%\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) Zero-Ratio: 80.87%\n",
      "Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 76.84%\n",
      "Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 72.16%\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) Zero-Ratio: 78.46%\n",
      "Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 73.91%\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 67.78%\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) Zero-Ratio: 86.96%\n",
      "Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 75.37%\n",
      "Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False) Zero-Ratio: 92.11%\n",
      "Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 88.69%\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) Zero-Ratio: 91.78%\n",
      "Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 84.73%\n",
      "Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 90.57%\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) Zero-Ratio: 91.45%\n",
      "Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 86.65%\n",
      "Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 86.76%\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) Zero-Ratio: 92.14%\n",
      "Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 85.69%\n",
      "Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 87.06%\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) Zero-Ratio: 91.62%\n",
      "Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 85.90%\n",
      "Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 82.73%\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) Zero-Ratio: 92.00%\n",
      "Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 81.33%\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 75.85%\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) Zero-Ratio: 94.70%\n",
      "Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 80.26%\n",
      "Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False) Zero-Ratio: 93.49%\n",
      "Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 90.47%\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) Zero-Ratio: 96.38%\n",
      "Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 86.33%\n",
      "Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 94.60%\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) Zero-Ratio: 97.82%\n",
      "Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) Zero-Ratio: 89.61%\n"
     ]
    }
   ],
   "source": [
    "# ゼロ比率を表示\n",
    "for module in model.modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        print(\n",
    "            f\"{module} Zero-Ratio: {100.0 * float(torch.sum(module.weight == 0)) / float(module.weight.nelement()):.2f}%\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推論時間（永続化後）: 0.0291 秒\n"
     ]
    }
   ],
   "source": [
    "output = model(input_image)  # ウォームアップ\n",
    "\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    output = model(input_image)\n",
    "end_time = time.time()\n",
    "print(f\"推論時間（永続化後）: {end_time - start_time:.4f} 秒\")\n",
    "# Intel Core i7-12700 で 0.0270 秒\n",
    "# マスクをパラメータに永続化したのでオーバーヘッドはなくなるが、疎計算に対応していないので、密計算と同じ速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resnet50_sparse.onnx'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_onnx(model, \"resnet50_sparse.onnx\") # 疎モデルを ONNX 形式で保存"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
